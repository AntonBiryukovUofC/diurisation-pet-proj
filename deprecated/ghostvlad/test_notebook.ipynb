{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # trim zuck audio\n",
    "# import librosa\n",
    "# filename = '../data/raw/z-c-feisty.wav'\n",
    "# y, sr = librosa.load(filename, offset=64.0, duration=13.5)\n",
    "# librosa.output.write_wav('zuck_trimmed.wav', y, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # trim audio from aaron ramsey. audio directly from VOXCeleb. aaron ramsey is the celeb with label 2/5993 in voxlb2_train.txt\n",
    "# filename = 'Aaron Ramsey speaks to the press ahead of Wales v England.wav'\n",
    "# y, sr = librosa.load(filename, offset=12.0, duration=15)\n",
    "# librosa.output.write_wav('aaron_ramset.wav', y, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below is copied from taylorlu\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "# set up training configuration.\n",
    "parser.add_argument('--gpu', default='', type=str)\n",
    "parser.add_argument('--resume', default=r'pretrained/weights.h5', type=str)\n",
    "parser.add_argument('--data_path', default='4persons', type=str)\n",
    "# set up network configuration.\n",
    "parser.add_argument('--net', default='resnet34s', choices=['resnet34s', 'resnet34l'], type=str)\n",
    "parser.add_argument('--ghost_cluster', default=2, type=int)\n",
    "parser.add_argument('--vlad_cluster', default=8, type=int)\n",
    "parser.add_argument('--bottleneck_dim', default=512, type=int)\n",
    "parser.add_argument('--aggregation_mode', default='gvlad', choices=['avg', 'vlad', 'gvlad'], type=str)\n",
    "# set up learning rate, training loss and optimizer.\n",
    "parser.add_argument('--loss', default='softmax', choices=['softmax', 'amsoftmax'], type=str)\n",
    "parser.add_argument('--test_type', default='normal', choices=['normal', 'hard', 'extend'], type=str)\n",
    "\n",
    "global args\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['activation_1', 'activation_10', 'activation_11', 'activation_12', 'activation_13', 'activation_14', 'activation_15', 'activation_16', 'activation_17', 'activation_18', 'activation_19', 'activation_2', 'activation_20', 'activation_21', 'activation_22', 'activation_23', 'activation_24', 'activation_25', 'activation_26', 'activation_27', 'activation_28', 'activation_29', 'activation_3', 'activation_30', 'activation_31', 'activation_32', 'activation_33', 'activation_34', 'activation_4', 'activation_5', 'activation_6', 'activation_7', 'activation_8', 'activation_9', 'add_1', 'add_10', 'add_11', 'add_2', 'add_3', 'add_4', 'add_5', 'add_6', 'add_7', 'add_8', 'add_9', 'conv1_1', 'conv2_a_1x1_increase', 'conv2_a_1x1_proj', 'conv2_a_1x1_reduce', 'conv2_a_3x3', 'conv2_b_1x1_increase', 'conv2_b_1x1_reduce', 'conv2_b_3x3', 'conv3_a_1x1_increase', 'conv3_a_1x1_proj', 'conv3_a_1x1_reduce', 'conv3_a_3x3', 'conv3_b_1x1_increase', 'conv3_b_1x1_reduce', 'conv3_b_3x3', 'conv3_c_1x1_increase', 'conv3_c_1x1_reduce', 'conv3_c_3x3', 'conv4_a_1x1_increase', 'conv4_a_1x1_proj', 'conv4_a_1x1_reduce', 'conv4_a_3x3', 'conv4_b_1x1_increase', 'conv4_b_1x1_reduce', 'conv4_b_3x3', 'conv4_c_1x1_increase', 'conv4_c_1x1_reduce', 'conv4_c_3x3', 'conv5_a_1x1_increase', 'conv5_a_1x1_proj', 'conv5_a_1x1_reduce', 'conv5_a_3x3', 'conv5_b_1x1_increase', 'conv5_b_1x1_reduce', 'conv5_b_3x3', 'conv5_c_1x1_increase', 'conv5_c_1x1_reduce', 'conv5_c_3x3', 'fc6', 'gvlad_center_assignment', 'gvlad_pool', 'input', 'lambda_1', 'max_pooling2d_1', 'mpool2', 'x_fc']>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "w1 = h5py.File(r'pretrained/weights.h5')\n",
    "allKeys = w1.keys()\n",
    "print(allKeys)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.81245893 -0.39149654\n",
      "1\n",
      "0.3055826 -0.37269655\n",
      "2\n",
      "0.61857986 -0.25030577\n",
      "3\n",
      "0.22437176 -0.21256928\n",
      "4\n",
      "0.28413346 -0.1989144\n",
      "5\n",
      "0.21027732 -0.1575586\n",
      "6\n",
      "0.2861945 -0.31525993\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "a = w1['x_fc']['x_fc']['kernel:0']\n",
    "for i in range(a.shape[0]):\n",
    "    print(i)\n",
    "    im = a[i,0,:,:]\n",
    "    print(im.max(),im.min())\n",
    "    plt.imshow(im,vmin=-0.0,vmax=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1, 512, 512)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\abiryukov\\AppData\\Local\\Continuum\\anaconda3\\envs\\pyBK\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 257, None, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_1/3x3_s1 (Conv2D)         (None, 257, None, 64 3136        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1_1/3x3_s1/bn (BatchNormali (None, 257, None, 64 256         conv1_1/3x3_s1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 257, None, 64 0           conv1_1/3x3_s1/bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, None, 64 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_a_1x1_reduce (Conv2D)     (None, 128, None, 48 3072        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_a_1x1_reduce/bn (BatchNor (None, 128, None, 48 192         conv2_a_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128, None, 48 0           conv2_a_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_a_3x3 (Conv2D)            (None, 128, None, 48 20736       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_a_3x3/bn (BatchNormalizat (None, 128, None, 48 192         conv2_a_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128, None, 48 0           conv2_a_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_a_1x1_increase (Conv2D)   (None, 128, None, 96 4608        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_a_1x1_proj (Conv2D)       (None, 128, None, 96 6144        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_a_1x1_increase/bn (BatchN (None, 128, None, 96 384         conv2_a_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2_a_1x1_proj/bn (BatchNorma (None, 128, None, 96 384         conv2_a_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, None, 96 0           conv2_a_1x1_increase/bn[0][0]    \n",
      "                                                                 conv2_a_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, None, 96 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_b_1x1_reduce (Conv2D)     (None, 128, None, 48 4608        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_b_1x1_reduce/bn (BatchNor (None, 128, None, 48 192         conv2_b_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, None, 48 0           conv2_b_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_b_3x3 (Conv2D)            (None, 128, None, 48 20736       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_b_3x3/bn (BatchNormalizat (None, 128, None, 48 192         conv2_b_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128, None, 48 0           conv2_b_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_b_1x1_increase (Conv2D)   (None, 128, None, 96 4608        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_b_1x1_increase/bn (BatchN (None, 128, None, 96 384         conv2_b_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128, None, 96 0           conv2_b_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 128, None, 96 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_a_1x1_reduce (Conv2D)     (None, 64, None, 96) 9216        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_a_1x1_reduce/bn (BatchNor (None, 64, None, 96) 384         conv3_a_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, None, 96) 0           conv3_a_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_a_3x3 (Conv2D)            (None, 64, None, 96) 82944       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_a_3x3/bn (BatchNormalizat (None, 64, None, 96) 384         conv3_a_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, None, 96) 0           conv3_a_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_a_1x1_increase (Conv2D)   (None, 64, None, 128 12288       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_a_1x1_proj (Conv2D)       (None, 64, None, 128 12288       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_a_1x1_increase/bn (BatchN (None, 64, None, 128 512         conv3_a_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_a_1x1_proj/bn (BatchNorma (None, 64, None, 128 512         conv3_a_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, None, 128 0           conv3_a_1x1_increase/bn[0][0]    \n",
      "                                                                 conv3_a_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, None, 128 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_b_1x1_reduce (Conv2D)     (None, 64, None, 96) 12288       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_b_1x1_reduce/bn (BatchNor (None, 64, None, 96) 384         conv3_b_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, None, 96) 0           conv3_b_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_b_3x3 (Conv2D)            (None, 64, None, 96) 82944       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_b_3x3/bn (BatchNormalizat (None, 64, None, 96) 384         conv3_b_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, None, 96) 0           conv3_b_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_b_1x1_increase (Conv2D)   (None, 64, None, 128 12288       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_b_1x1_increase/bn (BatchN (None, 64, None, 128 512         conv3_b_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, None, 128 0           conv3_b_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, None, 128 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_c_1x1_reduce (Conv2D)     (None, 64, None, 96) 12288       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_c_1x1_reduce/bn (BatchNor (None, 64, None, 96) 384         conv3_c_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 64, None, 96) 0           conv3_c_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_c_3x3 (Conv2D)            (None, 64, None, 96) 82944       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_c_3x3/bn (BatchNormalizat (None, 64, None, 96) 384         conv3_c_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 64, None, 96) 0           conv3_c_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_c_1x1_increase (Conv2D)   (None, 64, None, 128 12288       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_c_1x1_increase/bn (BatchN (None, 64, None, 128 512         conv3_c_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 64, None, 128 0           conv3_c_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 64, None, 128 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_a_1x1_reduce (Conv2D)     (None, 32, None, 128 16384       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_a_1x1_reduce/bn (BatchNor (None, 32, None, 128 512         conv4_a_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, None, 128 0           conv4_a_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_a_3x3 (Conv2D)            (None, 32, None, 128 147456      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_a_3x3/bn (BatchNormalizat (None, 32, None, 128 512         conv4_a_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, None, 128 0           conv4_a_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_a_1x1_increase (Conv2D)   (None, 32, None, 256 32768       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_a_1x1_proj (Conv2D)       (None, 32, None, 256 32768       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_a_1x1_increase/bn (BatchN (None, 32, None, 256 1024        conv4_a_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_a_1x1_proj/bn (BatchNorma (None, 32, None, 256 1024        conv4_a_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, None, 256 0           conv4_a_1x1_increase/bn[0][0]    \n",
      "                                                                 conv4_a_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, None, 256 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_b_1x1_reduce (Conv2D)     (None, 32, None, 128 32768       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_b_1x1_reduce/bn (BatchNor (None, 32, None, 128 512         conv4_b_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, None, 128 0           conv4_b_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_b_3x3 (Conv2D)            (None, 32, None, 128 147456      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_b_3x3/bn (BatchNormalizat (None, 32, None, 128 512         conv4_b_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, None, 128 0           conv4_b_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_b_1x1_increase (Conv2D)   (None, 32, None, 256 32768       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_b_1x1_increase/bn (BatchN (None, 32, None, 256 1024        conv4_b_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, None, 256 0           conv4_b_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, None, 256 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_c_1x1_reduce (Conv2D)     (None, 32, None, 128 32768       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_c_1x1_reduce/bn (BatchNor (None, 32, None, 128 512         conv4_c_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, None, 128 0           conv4_c_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_c_3x3 (Conv2D)            (None, 32, None, 128 147456      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_c_3x3/bn (BatchNormalizat (None, 32, None, 128 512         conv4_c_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, None, 128 0           conv4_c_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_c_1x1_increase (Conv2D)   (None, 32, None, 256 32768       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_c_1x1_increase/bn (BatchN (None, 32, None, 256 1024        conv4_c_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, None, 256 0           conv4_c_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 32, None, 256 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_a_1x1_reduce (Conv2D)     (None, 16, None, 256 65536       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_a_1x1_reduce/bn (BatchNor (None, 16, None, 256 1024        conv5_a_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, None, 256 0           conv5_a_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_a_3x3 (Conv2D)            (None, 16, None, 256 589824      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_a_3x3/bn (BatchNormalizat (None, 16, None, 256 1024        conv5_a_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, None, 256 0           conv5_a_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_a_1x1_increase (Conv2D)   (None, 16, None, 512 131072      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_a_1x1_proj (Conv2D)       (None, 16, None, 512 131072      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_a_1x1_increase/bn (BatchN (None, 16, None, 512 2048        conv5_a_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_a_1x1_proj/bn (BatchNorma (None, 16, None, 512 2048        conv5_a_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, None, 512 0           conv5_a_1x1_increase/bn[0][0]    \n",
      "                                                                 conv5_a_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, None, 512 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_b_1x1_reduce (Conv2D)     (None, 16, None, 256 131072      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_b_1x1_reduce/bn (BatchNor (None, 16, None, 256 1024        conv5_b_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, None, 256 0           conv5_b_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_b_3x3 (Conv2D)            (None, 16, None, 256 589824      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_b_3x3/bn (BatchNormalizat (None, 16, None, 256 1024        conv5_b_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, None, 256 0           conv5_b_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_b_1x1_increase (Conv2D)   (None, 16, None, 512 131072      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_b_1x1_increase/bn (BatchN (None, 16, None, 512 2048        conv5_b_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, None, 512 0           conv5_b_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, None, 512 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_c_1x1_reduce (Conv2D)     (None, 16, None, 256 131072      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_c_1x1_reduce/bn (BatchNor (None, 16, None, 256 1024        conv5_c_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, None, 256 0           conv5_c_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_c_3x3 (Conv2D)            (None, 16, None, 256 589824      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_c_3x3/bn (BatchNormalizat (None, 16, None, 256 1024        conv5_c_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, None, 256 0           conv5_c_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_c_1x1_increase (Conv2D)   (None, 16, None, 512 131072      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_c_1x1_increase/bn (BatchN (None, 16, None, 512 2048        conv5_c_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, None, 512 0           conv5_c_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, None, 512 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mpool2 (MaxPooling2D)           (None, 7, None, 512) 0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "x_fc (Conv2D)                   (None, 1, None, 512) 1835520     mpool2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gvlad_center_assignment (Conv2D (None, 1, None, 10)  35850       mpool2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gvlad_pool (VladPooling)        (None, 4096)         5120        x_fc[0][0]                       \n",
      "                                                                 gvlad_center_assignment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "prediction_dan (Dense)          (None, 5994)         24551424    gvlad_pool[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 30,132,170\n",
      "Trainable params: 30,118,154\n",
      "Non-trainable params: 14,016\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import model\n",
    "# ==================================\n",
    "#       Get Train/Val.\n",
    "# ==================================\n",
    "\n",
    "unique_list = 'aaron_ramset.wav'\n",
    "\n",
    "# ==================================\n",
    "#       Get Model\n",
    "# ==================================\n",
    "# construct the data generator.\n",
    "params = {'dim': (257, None, 1),\n",
    "          'nfft': 512,\n",
    "          'min_slice': 720,\n",
    "          'win_length': 400,\n",
    "          'hop_length': 160,\n",
    "          'n_classes': 5994,\n",
    "          'sampling_rate': 16000,\n",
    "          'normalize': True,\n",
    "          }\n",
    "\n",
    "network_eval1 = model.vggvox_resnet2d_icassp(input_dim=params['dim'],\n",
    "                                            num_class=params['n_classes'],\n",
    "                                            mode='eval', args=args)\n",
    "network_eval1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> successfully loading model pretrained/weights.h5.\n",
      "==> start testing.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if args.resume:\n",
    "    # ==> get real_model from arguments input,\n",
    "    # load the model if the imag_model == real_model.\n",
    "    if os.path.isfile(args.resume):\n",
    "        network_eval1.load_weights(os.path.join(args.resume), by_name=True)\n",
    "        print('==> successfully loading model {}.'.format(args.resume))\n",
    "    else:\n",
    "        raise IOError(\"==> no checkpoint found at '{}'\".format(args.resume))\n",
    "else:\n",
    "    raise IOError('==> please type in the model to load')\n",
    "\n",
    "print('==> start testing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess\n",
    "specs = preprocess.load_data(unique_list, split=False, win_length=params['win_length'], sr=params['sampling_rate'],\n",
    "                     hop_length=params['hop_length'], n_fft=params['nfft'],\n",
    "                     min_slice=params['min_slice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 257, 1206, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "specs = np.expand_dims(np.expand_dims(specs[0], 0), -1)\n",
    "specs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = network_eval1.predict(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21c071985c0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(v[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "w1 = h5py.File(r'pretrained/weights.h5')\n",
    "allKeys = w1.keys()\n",
    "print(allKeys)\n",
    "\n",
    "'../models/speaker_embedding/train/VoxCeleb.SpeakerVerification.VoxCeleb1.train/weights/2000.pt'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
