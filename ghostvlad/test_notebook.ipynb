{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim zuck audio\n",
    "import librosa\n",
    "filename = 'z-c-feisty.wav'\n",
    "y, sr = librosa.load(filename, offset=64.0, duration=13.5)\n",
    "librosa.output.write_wav('zuck_trimmed.wav', y, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim audio from aaron ramsey. audio directly from VOXCeleb. aaron ramsey is the celeb with label 2/5993 in voxlb2_train.txt\n",
    "filename = 'Aaron Ramsey speaks to the press ahead of Wales v England.wav'\n",
    "y, sr = librosa.load(filename, offset=12.0, duration=15)\n",
    "librosa.output.write_wav('aaron_ramset.wav', y, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below is copied from taylorlu\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "# set up training configuration.\n",
    "parser.add_argument('--gpu', default='', type=str)\n",
    "parser.add_argument('--resume', default=r'pretrained/weights.h5', type=str)\n",
    "parser.add_argument('--data_path', default='4persons', type=str)\n",
    "# set up network configuration.\n",
    "parser.add_argument('--net', default='resnet34s', choices=['resnet34s', 'resnet34l'], type=str)\n",
    "parser.add_argument('--ghost_cluster', default=2, type=int)\n",
    "parser.add_argument('--vlad_cluster', default=8, type=int)\n",
    "parser.add_argument('--bottleneck_dim', default=512, type=int)\n",
    "parser.add_argument('--aggregation_mode', default='gvlad', choices=['avg', 'vlad', 'gvlad'], type=str)\n",
    "# set up learning rate, training loss and optimizer.\n",
    "parser.add_argument('--loss', default='softmax', choices=['softmax', 'amsoftmax'], type=str)\n",
    "parser.add_argument('--test_type', default='normal', choices=['normal', 'hard', 'extend'], type=str)\n",
    "\n",
    "global args\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 257, None, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_1/3x3_s1 (Conv2D)         (None, 257, None, 64 3136        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1_1/3x3_s1/bn (BatchNormali (None, 257, None, 64 256         conv1_1/3x3_s1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 257, None, 64 0           conv1_1/3x3_s1/bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, None, 64 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_a_1x1_reduce (Conv2D)     (None, 128, None, 48 3072        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_a_1x1_reduce/bn (BatchNor (None, 128, None, 48 192         conv2_a_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 128, None, 48 0           conv2_a_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_a_3x3 (Conv2D)            (None, 128, None, 48 20736       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_a_3x3/bn (BatchNormalizat (None, 128, None, 48 192         conv2_a_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128, None, 48 0           conv2_a_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_a_1x1_increase (Conv2D)   (None, 128, None, 96 4608        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_a_1x1_proj (Conv2D)       (None, 128, None, 96 6144        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2_a_1x1_increase/bn (BatchN (None, 128, None, 96 384         conv2_a_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2_a_1x1_proj/bn (BatchNorma (None, 128, None, 96 384         conv2_a_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 128, None, 96 0           conv2_a_1x1_increase/bn[0][0]    \n",
      "                                                                 conv2_a_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, None, 96 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_b_1x1_reduce (Conv2D)     (None, 128, None, 48 4608        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_b_1x1_reduce/bn (BatchNor (None, 128, None, 48 192         conv2_b_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, None, 48 0           conv2_b_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_b_3x3 (Conv2D)            (None, 128, None, 48 20736       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_b_3x3/bn (BatchNormalizat (None, 128, None, 48 192         conv2_b_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128, None, 48 0           conv2_b_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2_b_1x1_increase (Conv2D)   (None, 128, None, 96 4608        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2_b_1x1_increase/bn (BatchN (None, 128, None, 96 384         conv2_b_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128, None, 96 0           conv2_b_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 128, None, 96 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_a_1x1_reduce (Conv2D)     (None, 64, None, 96) 9216        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_a_1x1_reduce/bn (BatchNor (None, 64, None, 96) 384         conv3_a_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, None, 96) 0           conv3_a_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_a_3x3 (Conv2D)            (None, 64, None, 96) 82944       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_a_3x3/bn (BatchNormalizat (None, 64, None, 96) 384         conv3_a_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, None, 96) 0           conv3_a_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_a_1x1_increase (Conv2D)   (None, 64, None, 128 12288       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_a_1x1_proj (Conv2D)       (None, 64, None, 128 12288       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3_a_1x1_increase/bn (BatchN (None, 64, None, 128 512         conv3_a_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_a_1x1_proj/bn (BatchNorma (None, 64, None, 128 512         conv3_a_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 64, None, 128 0           conv3_a_1x1_increase/bn[0][0]    \n",
      "                                                                 conv3_a_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, None, 128 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_b_1x1_reduce (Conv2D)     (None, 64, None, 96) 12288       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_b_1x1_reduce/bn (BatchNor (None, 64, None, 96) 384         conv3_b_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, None, 96) 0           conv3_b_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_b_3x3 (Conv2D)            (None, 64, None, 96) 82944       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_b_3x3/bn (BatchNormalizat (None, 64, None, 96) 384         conv3_b_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, None, 96) 0           conv3_b_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_b_1x1_increase (Conv2D)   (None, 64, None, 128 12288       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_b_1x1_increase/bn (BatchN (None, 64, None, 128 512         conv3_b_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 64, None, 128 0           conv3_b_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, None, 128 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_c_1x1_reduce (Conv2D)     (None, 64, None, 96) 12288       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_c_1x1_reduce/bn (BatchNor (None, 64, None, 96) 384         conv3_c_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 64, None, 96) 0           conv3_c_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3_c_3x3 (Conv2D)            (None, 64, None, 96) 82944       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_c_3x3/bn (BatchNormalizat (None, 64, None, 96) 384         conv3_c_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 64, None, 96) 0           conv3_c_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv3_c_1x1_increase (Conv2D)   (None, 64, None, 128 12288       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv3_c_1x1_increase/bn (BatchN (None, 64, None, 128 512         conv3_c_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 64, None, 128 0           conv3_c_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 64, None, 128 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_a_1x1_reduce (Conv2D)     (None, 32, None, 128 16384       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_a_1x1_reduce/bn (BatchNor (None, 32, None, 128 512         conv4_a_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, None, 128 0           conv4_a_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_a_3x3 (Conv2D)            (None, 32, None, 128 147456      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_a_3x3/bn (BatchNormalizat (None, 32, None, 128 512         conv4_a_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, None, 128 0           conv4_a_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_a_1x1_increase (Conv2D)   (None, 32, None, 256 32768       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_a_1x1_proj (Conv2D)       (None, 32, None, 256 32768       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_a_1x1_increase/bn (BatchN (None, 32, None, 256 1024        conv4_a_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_a_1x1_proj/bn (BatchNorma (None, 32, None, 256 1024        conv4_a_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 32, None, 256 0           conv4_a_1x1_increase/bn[0][0]    \n",
      "                                                                 conv4_a_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, None, 256 0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_b_1x1_reduce (Conv2D)     (None, 32, None, 128 32768       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_b_1x1_reduce/bn (BatchNor (None, 32, None, 128 512         conv4_b_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, None, 128 0           conv4_b_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_b_3x3 (Conv2D)            (None, 32, None, 128 147456      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_b_3x3/bn (BatchNormalizat (None, 32, None, 128 512         conv4_b_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, None, 128 0           conv4_b_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_b_1x1_increase (Conv2D)   (None, 32, None, 256 32768       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_b_1x1_increase/bn (BatchN (None, 32, None, 256 1024        conv4_b_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 32, None, 256 0           conv4_b_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, None, 256 0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_c_1x1_reduce (Conv2D)     (None, 32, None, 128 32768       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_c_1x1_reduce/bn (BatchNor (None, 32, None, 128 512         conv4_c_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, None, 128 0           conv4_c_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_c_3x3 (Conv2D)            (None, 32, None, 128 147456      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_c_3x3/bn (BatchNormalizat (None, 32, None, 128 512         conv4_c_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, None, 128 0           conv4_c_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv4_c_1x1_increase (Conv2D)   (None, 32, None, 256 32768       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_c_1x1_increase/bn (BatchN (None, 32, None, 256 1024        conv4_c_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 32, None, 256 0           conv4_c_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 32, None, 256 0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_a_1x1_reduce (Conv2D)     (None, 16, None, 256 65536       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_a_1x1_reduce/bn (BatchNor (None, 16, None, 256 1024        conv5_a_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, None, 256 0           conv5_a_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_a_3x3 (Conv2D)            (None, 16, None, 256 589824      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_a_3x3/bn (BatchNormalizat (None, 16, None, 256 1024        conv5_a_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, None, 256 0           conv5_a_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_a_1x1_increase (Conv2D)   (None, 16, None, 512 131072      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_a_1x1_proj (Conv2D)       (None, 16, None, 512 131072      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_a_1x1_increase/bn (BatchN (None, 16, None, 512 2048        conv5_a_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_a_1x1_proj/bn (BatchNorma (None, 16, None, 512 2048        conv5_a_1x1_proj[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, None, 512 0           conv5_a_1x1_increase/bn[0][0]    \n",
      "                                                                 conv5_a_1x1_proj/bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, None, 512 0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_b_1x1_reduce (Conv2D)     (None, 16, None, 256 131072      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_b_1x1_reduce/bn (BatchNor (None, 16, None, 256 1024        conv5_b_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, None, 256 0           conv5_b_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_b_3x3 (Conv2D)            (None, 16, None, 256 589824      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_b_3x3/bn (BatchNormalizat (None, 16, None, 256 1024        conv5_b_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, None, 256 0           conv5_b_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_b_1x1_increase (Conv2D)   (None, 16, None, 512 131072      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_b_1x1_increase/bn (BatchN (None, 16, None, 512 2048        conv5_b_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, None, 512 0           conv5_b_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, None, 512 0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_c_1x1_reduce (Conv2D)     (None, 16, None, 256 131072      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_c_1x1_reduce/bn (BatchNor (None, 16, None, 256 1024        conv5_c_1x1_reduce[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, None, 256 0           conv5_c_1x1_reduce/bn[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv5_c_3x3 (Conv2D)            (None, 16, None, 256 589824      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_c_3x3/bn (BatchNormalizat (None, 16, None, 256 1024        conv5_c_3x3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, None, 256 0           conv5_c_3x3/bn[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv5_c_1x1_increase (Conv2D)   (None, 16, None, 512 131072      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_c_1x1_increase/bn (BatchN (None, 16, None, 512 2048        conv5_c_1x1_increase[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, None, 512 0           conv5_c_1x1_increase/bn[0][0]    \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, None, 512 0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mpool2 (MaxPooling2D)           (None, 7, None, 512) 0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "x_fc (Conv2D)                   (None, 1, None, 512) 1835520     mpool2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gvlad_center_assignment (Conv2D (None, 1, None, 10)  35850       mpool2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gvlad_pool (VladPooling)        (None, 4096)         5120        x_fc[0][0]                       \n",
      "                                                                 gvlad_center_assignment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "prediction_dan (Dense)          (None, 5994)         24551424    gvlad_pool[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 30,132,170\n",
      "Trainable params: 30,118,154\n",
      "Non-trainable params: 14,016\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import model\n",
    "# ==================================\n",
    "#       Get Train/Val.\n",
    "# ==================================\n",
    "\n",
    "unique_list = 'aaron_ramset.wav'\n",
    "\n",
    "# ==================================\n",
    "#       Get Model\n",
    "# ==================================\n",
    "# construct the data generator.\n",
    "params = {'dim': (257, None, 1),\n",
    "          'nfft': 512,\n",
    "          'min_slice': 720,\n",
    "          'win_length': 400,\n",
    "          'hop_length': 160,\n",
    "          'n_classes': 5994,\n",
    "          'sampling_rate': 16000,\n",
    "          'normalize': True,\n",
    "          }\n",
    "\n",
    "network_eval1 = model.vggvox_resnet2d_icassp(input_dim=params['dim'],\n",
    "                                            num_class=params['n_classes'],\n",
    "                                            mode='eval', args=args)\n",
    "network_eval1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> successfully loading model pretrained/weights.h5.\n",
      "==> start testing.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if args.resume:\n",
    "    # ==> get real_model from arguments input,\n",
    "    # load the model if the imag_model == real_model.\n",
    "    if os.path.isfile(args.resume):\n",
    "        network_eval1.load_weights(os.path.join(args.resume), by_name=True)\n",
    "        print('==> successfully loading model {}.'.format(args.resume))\n",
    "    else:\n",
    "        raise IOError(\"==> no checkpoint found at '{}'\".format(args.resume))\n",
    "else:\n",
    "    raise IOError('==> please type in the model to load')\n",
    "\n",
    "print('==> start testing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess\n",
    "specs = preprocess.load_data(unique_list, split=False, win_length=params['win_length'], sr=params['sampling_rate'],\n",
    "                     hop_length=params['hop_length'], n_fft=params['nfft'],\n",
    "                     min_slice=params['min_slice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 257, 1206, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "specs = np.expand_dims(np.expand_dims(specs[0], 0), -1)\n",
    "specs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = network_eval1.predict(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = []\n",
    "feats += [v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = np.array(feats)[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4024"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find index with maximum probability to reference with voxlb2_train.txt\n",
    "ind = np.argmax(feats)\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
